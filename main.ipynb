{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998c25f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "import matplotlib.pyplot as plt \n",
    "import timeit \n",
    "\n",
    "#creating sin wave for input values \n",
    "T = 20\n",
    "L = 1000\n",
    "N = 100 \n",
    "\n",
    "x = np.empty((N, L), np.float32 )\n",
    "x[:] = np.array(range(L)) + np.random.randint(-4 * T, 4 * T, N).reshape(N, 1) \n",
    "y = np.sin(x / 1.0 / T).astype(np.float32)\n",
    "\n",
    "#torch.save(data, open('traindata.pt', 'wb'))\n",
    "#creating and LSTM Predictor\n",
    "class Sequence(nn.Module):\n",
    "    def __init__(self,n_hidden = 51):\n",
    "        super(Sequence, self).__init__()\n",
    "        self.n_hidden = n_hidden\n",
    "        #lstm cell1 & cells2, linear layer for prediction \n",
    "        self.lstm1 = nn.LSTMCell(1, self.n_hidden)\n",
    "        self.lstm2 = nn.LSTMCell(self.n_hidden, self.n_hidden ) \n",
    "        self.linear = nn.Linear(self.n_hidden, 1) \n",
    "        \n",
    "    def forward(self, x, future = 0): \n",
    "        outputs = []\n",
    "        n_samples = x.size(0)\n",
    "        h_t = torch.zeros(n_samples, self.n_hidden, dtype=torch.float32) \n",
    "        c_t = torch.zeros(n_samples, self.n_hidden, dtype=torch.float32) \n",
    "        h_t2 = torch.zeros(n_samples, self.n_hidden, dtype=torch.float32) \n",
    "        c_t2 = torch.zeros(n_samples, self.n_hidden, dtype=torch.float32) \n",
    "        for input_t in x.split(1, dim=1):\n",
    "            h_t, c_t = self.lstm1(input_t, (h_t, c_t)) \n",
    "            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2)) \n",
    "            output = self.linear(h_t2) \n",
    "            outputs.append(output) \n",
    "        # if we should predict the future \n",
    "        for i in range(future): \n",
    "            h_t, c_t = self.lstm1(output, (h_t, c_t))\n",
    "            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))\n",
    "            output = self.linear(h_t2) \n",
    "            outputs.append(output)\n",
    "        outputs = torch.cat(outputs, dim=1) \n",
    "        return outputs \n",
    "\n",
    "\n",
    "    #load data and make training set\n",
    "    # y= 100 , 1000\n",
    "train_input = torch.from_numpy(y[3:, :-1]) #97, 999 \n",
    "train_target = torch.from_numpy(y[3:, 1:]) #97, 999\n",
    "test_input = torch.from_numpy(y[:3, :-1]) # 3, 999\n",
    "test_target = torch.from_numpy(y[:3, 1:]) # 3, 999 \n",
    "    \n",
    "# build the model\n",
    "model = Sequence() \n",
    "criterion = nn.MSELoss() \n",
    "    \n",
    "# use LBFGS as optimizer since we can load the whole data to train \n",
    "optimizer = optim.LBFGS(model.parameters(), lr=0.8) \n",
    "start = timeit.default_timer() \n",
    "    \n",
    "#begin to train \n",
    "n_steps = 10\n",
    "for i in range(n_steps):\n",
    "    print('Step', i) #change \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        out = model(train_input)\n",
    "        loss = criterion(out, train_target) \n",
    "        print('loss:', loss.item()) \n",
    "        loss.backward() #back propagation \n",
    "        return loss \n",
    "    optimizer.step(closure)\n",
    "            \n",
    "# begin to predict, no need to track gradient here \n",
    "    with torch.no_grad():\n",
    "        future = 1000 #predict steps can increase \n",
    "        pred = model(test_input, future=future) \n",
    "        loss = criterion(pred[:,:-future], test_target) \n",
    "        print('test loss:', loss.item())\n",
    "        y = pred.detach().numpy() # numerical outputs \n",
    "        \n",
    "    # draw the result \n",
    "    plt.figure(figsize=(12,6)) \n",
    "    plt.title('Predict future values for time sequences\\n(Dashlines are predicted values)' f\"\\nstep{i+1}\", fontsize=20) \n",
    "    plt.xlabel('x', fontsize=20)\n",
    "    plt.ylabel('y', fontsize=20) \n",
    "    plt.xticks(fontsize=20) \n",
    "    plt.yticks(fontsize=20) \n",
    "    n = train_input.shape[1] #999 \n",
    "    def draw(yi, color):\n",
    "        plt.plot(np.arange(n), yi[:n], color, linewidth = 2.0) \n",
    "        plt.plot(np.arange(n, n+future), yi[n:], color + ':', linewidth = 2.0) \n",
    "    draw(y[0], 'r')\n",
    "    draw(y[1], 'g')\n",
    "    draw(y[2], 'b') \n",
    "    plt.savefig('predict%d.pdf'%i) \n",
    "    plt.close() \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
